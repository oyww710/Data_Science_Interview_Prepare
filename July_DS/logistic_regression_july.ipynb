{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-30T17:02:33.093387Z","iopub.execute_input":"2021-07-30T17:02:33.093775Z","iopub.status.idle":"2021-07-30T17:02:33.104336Z","shell.execute_reply.started":"2021-07-30T17:02:33.093680Z","shell.execute_reply":"2021-07-30T17:02:33.103255Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from sklearn.datasets import load_breast_cancer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\n# 获取乳腺癌数据集\ncancer = load_breast_cancer()\n# 获取数据集特征\nX = cancer.data\n# 获取数据集标记\ny = cancer.target\n# 特征归一化到 [0,1] 范围内：提升模型收敛速度\nX = MinMaxScaler().fit_transform(X)\n# 划分训练集和测试集\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=2020)\n\n# 2. 逻辑回归算法实现\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nclass LogisticRegression:\n    '''逻辑回归算法实现'''\n\n    def __init__(self,alpha=0.1,epoch=5000,fit_bias=True,threshold=0.5):\n        '''\n        alpha: 学习率，控制参数更新的幅度\n        epoch: 在整个训练集上训练迭代（参数更新）的次数\n        fit_bias: 是否训练偏置项参数\n        threshold：判定为正类的概率阈值\n        '''\n        self.alpha = alpha\n        self.epoch = epoch\n        # cost_record 记录每一次迭代后的经验风险\n        self.cost_record = []\n        self.fit_bias = fit_bias\n        self.threshold = threshold\n\n    # 概率预测函数\n    def predict_proba(self,X_test):\n        '''\n        X_test: m x n 的 numpy 二维数组\n        '''\n        # 模型有偏置项参数时：为每个测试样本增加特征 x_0 = 1\n        if self.fit_bias:\n            x_0 = np.ones(X_test.shape[0])\n            X_test = np.column_stack((x_0,X_test))\n\n        # 根据预测公式返回结果\n        z = np.dot(X_test,self.w)\n        return 1/(1+np.exp(-z))\n    \n    # 类别预测函数\n    def predict(self,X_test):\n        '''\n        X_test: m x n 的 numpy 二维数组\n        '''\n        probs = self.predict_proba(X_test)\n        results = map(lambda x:int(x>self.threshold),probs)\n        return np.array(list(results))\n        \n    # 模型训练：使用梯度下降法更新参数\n    def fit(self,X_train,y_train):\n        '''\n        X_train: m x n 的 numpy 二维数组\n        y_train：有 m 个元素的 numpy 一维数组\n        '''\n        # 训练偏置项参数时：为每个训练样本增加特征 x_0 = 1\n        if self.fit_bias:\n            x_0 = np.ones(X_train.shape[0])\n            X_train = np.column_stack((x_0,X_train))\n\n        # 训练样本数量\n        m = X_train.shape[0]\n        # 样本特征维数\n        n = X_train.shape[1]\n        # 初始模型参数\n        self.w = np.ones(n)\n        \n        # 模型参数迭代\n        for i in range(self.epoch):\n            # 计算训练样本预测值\n            z = np.dot(X_train,self.w)\n            y_pred = 1/(1+np.exp(-z))\n            # 计算训练集经验风险\n            cost = -(np.dot(y_train,np.log(y_pred))+\n                     np.dot(np.ones(m)-y_train,np.log(np.ones(m)-y_pred)))/m\n            # 记录训练集经验风险\n            self.cost_record.append(cost)\n            # 参数更新\n            self.w += self.alpha/m * np.dot(y_train-y_pred,X_train)\n        \n        # 保存模型\n        self.save_model()\n\n    # 显示经验风险的收敛趋势图\n    def polt_cost(self):\n        plt.plot(np.arange(self.epoch),self.cost_record)\n        plt.xlabel(\"epoch\")\n        plt.ylabel(\"cost\")\n        plt.show()\n\n    # 保存模型参数\n    def save_model(self):\n        np.savetxt(\"model.txt\",self.w)\n\n    # 加载模型参数\n    def load_model(self):\n        self.w = np.loadtxt('model.txt')\n\n\n# 3. 模型的训练和预测\n\nfrom sklearn import linear_model \n\n# 实例化一个对象\nmodel_1 = LogisticRegression(epoch=60000) \nmodel_2 = linear_model.LogisticRegression() \n# 在训练集上训练\nmodel_1.fit(X_train,y_train)\nmodel_2.fit(X_train,y_train)\n# 在测试集上预测\ny_pred_1 = model_1.predict(X_test)\ny_pred_2 = model_2.predict(X_test)\n\n# 4. 模型分类指标评估\n\nimport pandas as pd\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score\n\nmetrics = dict()\n\nacc_1 = accuracy_score(y_test,y_pred_1)\nacc_2 = accuracy_score(y_test,y_pred_2)\nmetrics['准确率'] = [acc_1,acc_2]\n\npre_1 = precision_score(y_test,y_pred_1)\npre_2 = precision_score(y_test,y_pred_2)\nmetrics['精确率'] = [pre_1,pre_2]\n\nrec_1 = recall_score(y_test,y_pred_1)\nrec_2 = recall_score(y_test,y_pred_2)\nmetrics['召回率'] = [rec_1,rec_2]\n\nf1_1 = f1_score(y_test,y_pred_1)\nf1_2 = f1_score(y_test,y_pred_2)\nmetrics['F1值'] = [f1_1,f1_2]\n\nauc_1 = roc_auc_score(y_test, model_1.predict_proba(X_test))\nauc_2 = roc_auc_score(y_test, model_2.predict_proba(X_test)[:,1])\nmetrics['AUC'] = [auc_1,auc_2]\n\ndf = pd.DataFrame(metrics,index=['model_1','model_2'])\n# 使得打印数据时可以纵向对齐\npd.set_option('display.unicode.east_asian_width', True)\nprint(df)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T17:02:44.349526Z","iopub.execute_input":"2021-07-30T17:02:44.349922Z","iopub.status.idle":"2021-07-30T17:02:53.794138Z","shell.execute_reply.started":"2021-07-30T17:02:44.349887Z","shell.execute_reply":"2021-07-30T17:02:53.793004Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"           准确率    精确率    召回率      F1值       AUC\nmodel_1  0.973684  0.984615  0.969697  0.977099  0.990846\nmodel_2  0.964912  0.942857  1.000000  0.970588  0.985795\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}